# Solution for Question 1
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, avg, count, round, desc, asc, udf
from pyspark.sql.window import Window
from pyspark.sql.functions import row_number
import re
from pyspark.sql.types import IntegerType
 
spark = SparkSession.builder.getOrCreate()
 
#movies_schema = 'movie_id int, title string, genres string'
#ratings_schema = 'userid int, movie_id int, rating float, `timestamp` int'
ratings_df = spark.read.csv('ratings.csv', header= True, inferSchema= True)
movies_df = spark.read.csv('movies.csv', header= True, inferSchema= True)
 
def extract_year(title):
   match = re.search(r'\((\d{4})\)', title)
   if match:
       return int(match.group(1))
   else:
       return None
 
extract_year_udf = udf(extract_year, IntegerType())
 
movies_df = movies_df.withColumn("year", extract_year_udf(col("title")))
 
filtered_movies_df = movies_df.filter((col("year") >= 2000) & (col("year") <= 2010))
 
# Join movies with ratings
movies_ratings_df = filtered_movies_df.join(ratings_df, "movieId")
ratings_summary_df = movies_ratings_df.groupBy("movieId", "title", "year").agg(max("rating").alias("total_ratings")
 
 
final_df = ranked_movies_df.orderBy(asc("yearâ€))
.select('year','movie_id','title','total_ratings','average_rating')